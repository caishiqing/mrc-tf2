model:
  max_input_length: 512
  max_answer_length: 8
  doc_stride: 128
  model_name_or_path: hfl/chinese-roberta-wwm-ext

train:
  batch_size: 8
  epochs: 10
  steps_per_epoch: 200
  learning_rate: !!float 2e-5
  warmup_proportion: 0.1
  valid_size: 0.1
  